{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bright-theater",
   "metadata": {},
   "source": [
    "#### Arcpy + Geopandas combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dependent-channel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Must be opened from ArcGIS Python Command Prompt (juptyter lab)\n",
    "# Must have signed into ArcGIS online? (run ArcGIS Pro)\n",
    "\n",
    "import arcpy\n",
    "from arcpy import env\n",
    "from arcpy.sa import *\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "peripheral-handy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def renameShapeField(inshp,infieldname,outfieldname):\n",
    "    '''renames a field in a shapefile using geopandas because arcpy doesn't support this.'''\n",
    "    ingdf = gpd.read_file(inshp)\n",
    "    ingdf.rename(columns={infieldname: outfieldname}, inplace=True)\n",
    "    ingdf.to_file(inshp)\n",
    "    print(f'Fieldname {infieldname} changed to {outfieldname} in shapefile.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "elementary-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs\n",
    "#DEMS\n",
    "# dem1 = Path(r\"D:\\Whiskeytown\\dem_diff\\brandy_creek\\dems\\orig\\brandy_dem2019.tif\")\n",
    "# dem2 = Path(r\"D:\\Whiskeytown\\dem_diff\\brandy_creek\\dems\\orig\\brandy_dem2020.tif\")\n",
    "dem1 = Path(r\"D:\\Whiskeytown\\dem_diff\\brandy_creek\\dems\\orig\\brandy_dem2018.tif\")\n",
    "dem2 = Path(r\"D:\\Whiskeytown\\dem_diff\\brandy_creek\\dems\\orig\\brandy_dem2019.tif\")\n",
    "\n",
    "#Stable polygons\n",
    "# stablepolyshp = Path(r\"D:\\Whiskeytown\\dem_diff\\brandy_creek\\shp\\Stable_poly_19-20_expanded.shp\")\n",
    "stablepolyshp = Path(r\"D:\\Whiskeytown\\dem_diff\\brandy_creek\\shp\\Stable_poly_18-19_expanded.shp\")\n",
    "\n",
    "#Output dod name stem\n",
    "dodnamestem = r\"DoD_19-18\"\n",
    "detrendnamestem = r\"Detrend_19-18_polyn\"\n",
    "\n",
    "#output dir\n",
    "demdiff_dir = Path(r\"D:\\Whiskeytown\\dem_diff\\brandy_creek\\demdiff19-18\")\n",
    "outdod_dir = Path(demdiff_dir, r\"dod\")\n",
    "outdod_unadj_dir  = Path(demdiff_dir, r\"dod\\unadj\")\n",
    "outdod_adj_dir  = Path(demdiff_dir, r\"dod\\adj\")\n",
    "outdod_pt_dir  = Path(demdiff_dir, r\"dod\\shp\")\n",
    "outtrendraster_dir = Path(demdiff_dir, r\"detrend\")\n",
    "outtrend_pt_dir = Path(demdiff_dir, r\"detrend\\shp\")\n",
    "scratch_dir = Path(demdiff_dir, r\"arcpyscratch\")\n",
    "\n",
    "#create parent if doesn't exist\n",
    "demdiff_dir.mkdir(parents=True, exist_ok=True)\n",
    "#create subdir if don't exist\n",
    "for direc in [outdod_dir, outdod_unadj_dir, outdod_adj_dir, outdod_pt_dir, outtrendraster_dir, outtrend_pt_dir, scratch_dir]:\n",
    "    direc.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # Set local variables\n",
    "# instablepointfeatures = Path(r\"D:\\Whiskeytown\\dem_diff\\brandy_creek\\dod\\shp\\DoD_20-19_unadj_pts_stable.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "manual-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment settings\n",
    "arcpy.env.workspace = str(scratch_dir)\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.compression = \"LZW\"\n",
    "\n",
    "env.extent = str(dem1)\n",
    "env.snapRaster = str(dem1)\n",
    "\n",
    "# Check out the ArcGIS Spatial Analyst extension license\n",
    "arcpy.CheckOutExtension(\"Spatial\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "sexual-forest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make unadjusted DoD\n",
    "outunadjdod = Path(outdod_unadj_dir,dodnamestem + r'_unadj.tif')\n",
    "\n",
    "dod = RasterCalculator([str(dem1), str(dem2)], [\"dem1\", \"dem2\"],\n",
    "                                       \"dem2-dem1\", \"FirstOf\", \"FirstOf\")\n",
    "\n",
    "dod.save(str(outunadjdod))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert DoD to point shapefile, then clip with stable polygons and rename field to 'dod_unadj'\n",
    "outstablept_shp = str(Path(outdod_pt_dir, outunadjdod.stem + r'_pts.shp')) #same as DoD, but '_pts.shp')\n",
    "\n",
    "arcpy.RasterToPoint_conversion(dod, r\"memory\\tempRasPt\", \"VALUE\");\n",
    "arcpy.Clip_analysis(r\"memory\\tempRasPt\", str(stablepolyshp), outstablept_shp, \"\");\n",
    "#rename field\n",
    "renameShapeField(outpointshape,'grid_code','dod_unadj')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "statistical-manor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating trend surface polynomial order 0...\n",
      "Creating trend surface polynomial order 1...\n",
      "Creating trend surface polynomial order 2...\n"
     ]
    }
   ],
   "source": [
    "#Calculate trend surface using all stable points (polynomial 0, 1 and 2)\n",
    "\n",
    "#Inputs/outputs\n",
    "stablept_shp = outstablept_shp #(from cell above)\n",
    "outtrendrasterstem = str(Path(outtrendraster_dir, detrendnamestem))\n",
    "\n",
    "zField = \"dod_unadj\"\n",
    "cellSize = 0.25\n",
    "# PolynomialOrder = 2 (set in loop)\n",
    "regressionType = \"LINEAR\"\n",
    "\n",
    "for polyn_order in [0, 1, 2]:\n",
    "    # Execute Trend\n",
    "    print(f'Creating trend surface polynomial order {polyn_order}...')\n",
    "    outTrend = Trend(stablept_shp, zField, cellSize, \n",
    "                     polyn_order, regressionType)\n",
    "    outTrend.save(outtrendrasterstem + str(polyn_order) + \".tif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "designed-leisure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Apply to DoD to evaluate visually\n",
    "# Adjustment order is:\n",
    "#     DoD - TrendRaster = AdjustedDoD\n",
    "# This is equivalent to adjusting DEM1:\n",
    "#      DEM2 - DEM1 - TrendRaster = AdjustedDoD\n",
    "# Since TrendRaster = DoD residual which should be zero.\n",
    "# For example:\n",
    "# DEM2 = 3, DEM1 = 5, DoD = -2, TrendRaster = -2\n",
    "# AdjustedDoD =  DEM2 - DEM1 - TrendRaster = 0\n",
    "#             =  3 - 5 -(-2) = 0\n",
    "#             =  DoD - TrendRaster = 0\n",
    "#             =  -2 -(-2) = 0\n",
    "# '''\n",
    "\n",
    "#inputs/outputs\n",
    "inunadjdod = str(outunadjdod) #from above cell\n",
    "intrendrasterstem = outtrendrasterstem #from cell above\n",
    "outadjdodstem = str(Path(outdod_adj_dir, dodnamestem + r'_adj_polyn_'))\n",
    "\n",
    "#loop through detrend surfaces and apply to DoD\n",
    "for polyn_order in [0,1,2]:\n",
    "    #apply adjustment\n",
    "    trendraster = intrendrasterstem + str(polyn_order) + '.tif'\n",
    "    adj = RasterCalculator([inunadjdod, trendraster], [\"dod\", \"trendraster\"],\n",
    "                                       \"dod-trendraster\", \"FirstOf\", \"FirstOf\")\n",
    "    adj.save(outadjdodstem + str(polyn_order) + '.tif')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "hawaiian-preliminary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling raster D:\\Whiskeytown\\dem_diff\\brandy_creek\\dod\\DOD_brandy_20-19_poly0adjust.tif ...\n",
      "Renaming field.\n",
      "Fieldname RASTERVALU changed to poly0resid in shapefile.\n",
      "Sampling raster D:\\Whiskeytown\\dem_diff\\brandy_creek\\dod\\DOD_brandy_20-19_poly1adjust.tif ...\n",
      "Renaming field.\n",
      "Fieldname RASTERVALU changed to poly1resid in shapefile.\n",
      "Sampling raster D:\\Whiskeytown\\dem_diff\\brandy_creek\\dod\\DOD_brandy_20-19_poly2adjust.tif ...\n",
      "Renaming field.\n",
      "Fieldname RASTERVALU changed to poly2resid in shapefile.\n",
      "dod_unadj mean = 0.0415556 \n",
      "dod_unadj std = 0.0587836 \n",
      "dod_unadj max = 1.36026 \n",
      "dod_unadj min = -0.3206482 \n",
      "\n",
      "\n",
      "poly0resid mean = -0.0 \n",
      "poly0resid std = 0.0587836 \n",
      "poly0resid max = 1.3187044 \n",
      "poly0resid min = -0.3622038 \n",
      "\n",
      "\n",
      "poly1resid mean = -0.0 \n",
      "poly1resid std = 0.051012 \n",
      "poly1resid max = 1.3005401 \n",
      "poly1resid min = -0.3364101 \n",
      "\n",
      "\n",
      "poly2resid mean = 7.08e-05 \n",
      "poly2resid std = 0.0492809 \n",
      "poly2resid max = 1.2729789 \n",
      "poly2resid min = -0.3268719 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Extract residual values from each adjusted DoD trend surface and evaluate bulk points\n",
    "\n",
    "stablept_shp = str(Path(outdod_pt_dir, outunadjdod.stem + r'_pts.shp')) #same as DoD, but '_pts.shp')\n",
    "inadjdodstem = str(Path(outdod_adj_dir, dodnamestem + r'_adj_polyn_'))\n",
    "outdetrendevalptshp = str(Path(outtrend_pt_dir, Path(outdod_pt_dir, outunadjdod.stem + r'_pts.shp') .stem + r'_detrend_eval.shp'))\n",
    "\n",
    "#copy stable points to eval file\n",
    "arcpy.Copy_management(stablept_shp, outdetrendevalptshp);\n",
    "\n",
    "#derive list of adjusted dods and output fieldnames for multi-raster extract\n",
    "inras_outfield_list = [[inadjdodstem + str(n) + '.tif', 'poly' + str(n) + 'resid'] for n in [0,1,2]]\n",
    "\n",
    "#extract adjusted dod residual values to points\n",
    "ExtractMultiValuesToPoints(outdetrendevalptshp, inras_outfield_list, \"NONE\")\n",
    "\n",
    "# Evaluate residual values\n",
    "#report    \n",
    "for col in ['dod_unadj','poly0resid', 'poly1resid', 'poly2resid']:\n",
    "    print(f'{col} mean = {str(round(tempgdf[col].mean(),7))} \\n'\n",
    "          f'{col} std = {str(round(tempgdf[col].std(),7))} \\n'\n",
    "          f'{col} max = {str(round(tempgdf[col].max(),7))} \\n'\n",
    "          f'{col} min = {str(round(tempgdf[col].min(),7))} \\n'\n",
    "          '\\n'\n",
    "         )\n",
    "\n",
    "#clean up \n",
    "for i in [0,1,2]:\n",
    "    arcpy.management.Delete(str(Path(outdetrendpath + '\\\\temp_detrendeval_' + str(i) + '.shp')));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-fifty",
   "metadata": {},
   "source": [
    "### Decide which trend surface to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "official-girlfriend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Residual Error\n",
    "# Subdivide stable polygons to use as test/train sets for residual error evaluation, then get poly and subdiv poly id onto points via intersection\n",
    "\n",
    "#inputs\n",
    "# target_subpoly_area = 9 # (9 = 144 points)size of subpolygons in m^2 (too small may result in overfitting of trend surface to validation points?)\n",
    "target_subpoly_area = 100 # (100 = 1600 pts) size of subpolygons in m^2(too small may result in overfitting of trend surface to validation points?)\n",
    "#points\n",
    "inPointFeatures = r\"D:\\Whiskeytown\\dem_diff\\brandy_creek\\dod\\shp\\DoD_19-18_unadj_pts_stable.shp\"\n",
    "outpointswithsubpolyid = r\"D:\\Whiskeytown\\dem_diff\\brandy_creek\\dod\\shp\\DoD_19-18_unadj_pts_stable_100m_subpolyid.shp\"\n",
    "#polygons\n",
    "stablepolyshp = r\"D:\\Whiskeytown\\dem_diff\\brandy_creek\\shp\\Stable_poly_18-19_expanded.shp\"\n",
    "outstablepolysubdivided = r\"D:\\Whiskeytown\\dem_diff\\brandy_creek\\shp\\Stable_poly_18-19_expanded_100m_subdivided.shp\"\n",
    "\n",
    "#subdivide polygon\n",
    "arcpy.SubdividePolygon_management(\n",
    "    stablepolyshp, outstablepolysubdivided, \"EQUAL_AREAS\",\"\", target_subpoly_area, \"\", \"\", \n",
    "    \"STACKED_BLOCKS\")\n",
    "\n",
    "#add subdiv poly id to poly attr table\n",
    "polygdf = gpd.read_file(outstablepolysubdivided)\n",
    "polygdf['subpolyid'] = polygdf.index\n",
    "polygdf.to_file(outstablepolysubdivided)\n",
    "\n",
    "#run spatial join to get 'subpolyid'\n",
    "ptgdf = gpd.read_file(inPointFeatures)\n",
    "\n",
    "#spatial join points with subdiv polygons to get polyid and subdividedpolyid on points for later test/train filter.\n",
    "ptwithpolygdf = gpd.sjoin(ptgdf, polygdf, how=\"left\", op='intersects')\n",
    "#write output shp\n",
    "ptwithpolygdf.to_file(outpointswithsubpolyid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "completed-reputation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021/28/01 17:09:32\n",
      "Beginning iteration 0 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 17:12:06\n",
      "Beginning iteration 1 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 17:14:26\n",
      "Beginning iteration 2 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 17:16:45\n",
      "Beginning iteration 3 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 17:19:06\n",
      "Beginning iteration 4 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 17:21:27\n",
      "Beginning iteration 5 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 17:23:47\n",
      "Beginning iteration 6 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 17:26:07\n",
      "Beginning iteration 7 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 17:28:28\n",
      "Beginning iteration 8 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 17:30:49\n",
      "Beginning iteration 9 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 17:33:09\n",
      "Beginning iteration 10 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 17:35:30\n",
      "Beginning iteration 11 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 17:37:50\n",
      "Beginning iteration 12 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 17:40:10\n",
      "Beginning iteration 13 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 17:42:30\n",
      "Beginning iteration 14 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 17:44:49\n",
      "Beginning iteration 15 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 17:46:51\n",
      "Beginning iteration 16 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 17:49:11\n",
      "Beginning iteration 17 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 17:51:31\n",
      "Beginning iteration 18 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 17:53:53\n",
      "Beginning iteration 19 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 17:55:59\n",
      "Beginning iteration 20 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 17:58:19\n",
      "Beginning iteration 21 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 18:00:21\n",
      "Beginning iteration 22 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 18:02:42\n",
      "Beginning iteration 23 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 18:05:01\n",
      "Beginning iteration 24 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 18:07:21\n",
      "Beginning iteration 25 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 18:09:41\n",
      "Beginning iteration 26 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 18:12:01\n",
      "Beginning iteration 27 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 18:14:20\n",
      "Beginning iteration 28 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 18:16:40\n",
      "Beginning iteration 29 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 18:18:47\n",
      "Beginning iteration 30 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 18:21:07\n",
      "Beginning iteration 31 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 18:23:27\n",
      "Beginning iteration 32 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 18:25:48\n",
      "Beginning iteration 33 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 18:28:08\n",
      "Beginning iteration 34 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 18:30:28\n",
      "Beginning iteration 35 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 18:32:49\n",
      "Beginning iteration 36 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 18:35:09\n",
      "Beginning iteration 37 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 18:37:29\n",
      "Beginning iteration 38 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 18:39:50\n",
      "Beginning iteration 39 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 18:42:10\n",
      "Beginning iteration 40 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 18:44:30\n",
      "Beginning iteration 41 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 18:46:51\n",
      "Beginning iteration 42 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 18:49:10\n",
      "Beginning iteration 43 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 18:51:31\n",
      "Beginning iteration 44 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 18:53:52\n",
      "Beginning iteration 45 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 18:56:12\n",
      "Beginning iteration 46 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 18:58:33\n",
      "Beginning iteration 47 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 19:00:53\n",
      "Beginning iteration 48 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 19:03:13\n",
      "Beginning iteration 49 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 19:05:32\n",
      "Beginning iteration 50 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 19:07:35\n",
      "Beginning iteration 51 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 19:09:54\n",
      "Beginning iteration 52 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 19:12:14\n",
      "Beginning iteration 53 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 19:14:34\n",
      "Beginning iteration 54 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 19:16:55\n",
      "Beginning iteration 55 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 19:19:14\n",
      "Beginning iteration 56 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 19:21:33\n",
      "Beginning iteration 57 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 19:23:54\n",
      "Beginning iteration 58 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 19:26:14\n",
      "Beginning iteration 59 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 19:28:34\n",
      "Beginning iteration 60 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 19:30:58\n",
      "Beginning iteration 61 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 19:33:20\n",
      "Beginning iteration 62 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 19:35:42\n",
      "Beginning iteration 63 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 19:38:01\n",
      "Beginning iteration 64 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 19:40:09\n",
      "Beginning iteration 65 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 19:42:29\n",
      "Beginning iteration 66 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 19:44:49\n",
      "Beginning iteration 67 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 19:47:09\n",
      "Beginning iteration 68 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 19:49:30\n",
      "Beginning iteration 69 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 19:51:50\n",
      "Beginning iteration 70 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 19:53:51\n",
      "Beginning iteration 71 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 19:56:11\n",
      "Beginning iteration 72 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 19:58:32\n",
      "Beginning iteration 73 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 20:00:51\n",
      "Beginning iteration 74 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 20:03:10\n",
      "Beginning iteration 75 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 20:05:30\n",
      "Beginning iteration 76 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 20:07:50\n",
      "Beginning iteration 77 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 20:10:10\n",
      "Beginning iteration 78 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 20:12:31\n",
      "Beginning iteration 79 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 20:14:50\n",
      "Beginning iteration 80 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 20:16:55\n",
      "Beginning iteration 81 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 20:19:16\n",
      "Beginning iteration 82 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 20:21:37\n",
      "Beginning iteration 83 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 20:23:58\n",
      "Beginning iteration 84 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 20:26:18\n",
      "Beginning iteration 85 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 20:28:38\n",
      "Beginning iteration 86 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 20:30:57\n",
      "Beginning iteration 87 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 20:33:17\n",
      "Beginning iteration 88 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 20:35:37\n",
      "Beginning iteration 89 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 20:37:58\n",
      "Beginning iteration 90 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 20:40:18\n",
      "Beginning iteration 91 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 20:42:37\n",
      "Beginning iteration 92 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 20:44:57\n",
      "Beginning iteration 93 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 20:47:18\n",
      "Beginning iteration 94 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 20:49:37\n",
      "Beginning iteration 95 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 20:51:57\n",
      "Beginning iteration 96 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 20:54:17\n",
      "Beginning iteration 97 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 20:56:36\n",
      "Beginning iteration 98 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 20:58:57\n",
      "Beginning iteration 99 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 21:01:18\n"
     ]
    }
   ],
   "source": [
    "#iterate and do test/train splits to evaluate by subpolygon\n",
    "print(datetime.now().strftime(\"%Y/%d/%m %H:%M:%S\"))    \n",
    "#number of iterations (~2-3 minutes each?)\n",
    "num_loops = 100\n",
    "\n",
    "#inputs\n",
    "pointswithsubpolyid = r\"D:\\Whiskeytown\\dem_diff\\brandy_creek\\dod\\shp\\DoD_19-18_unadj_pts_stable_100m_subpolyid.shp\"\n",
    "stablepolysubdivided = r\"D:\\Whiskeytown\\dem_diff\\brandy_creek\\shp\\Stable_poly_18-19_expanded_100m_subdivided.shp\"\n",
    "\n",
    "#load points with subpoly id into gdf to be filtered\n",
    "ptwithpolygdf = gpd.read_file(pointswithsubpolyid)\n",
    "\n",
    "#trend surface details\n",
    "zField = \"dod_unadj\"\n",
    "cellSize = 0.25\n",
    "PolynomialOrder = 2\n",
    "regressionType = \"LINEAR\"\n",
    "\n",
    "#result df\n",
    "resultsdf = pd.DataFrame(columns = ['bulk_pt_mean','bulk_pt_std','all_poly_mean','all_poly_std','paved_poly_mean','paved_poly_std','unpaved_poly_mean','unpaved_poly_std'])\n",
    "#percent of poly to use for train \n",
    "trainfrac = 0.6\n",
    "\n",
    "for i in range(num_loops):\n",
    "    #clean up scratch dir first (leave results of final iteration in scratch to let user see them)\n",
    "    for fn in [r\"\\temp_trainpoly.shp\", r\"\\temp_valpoly.shp\", r\"\\temp_trainpoint.shp\", r\"\\temp_valpoint.shp\", r\"\\temp_valpoint_withdetrend.shp\",r\"\\temp_trendraster.tif\"]:\n",
    "        arcpy.management.Delete(arcpy.env.workspace + fn)\n",
    "    print(f'Beginning iteration {i} ...')\n",
    "    #subset poly to test/train\n",
    "    arcpy.ga.SubsetFeatures(stablepolysubdivided, \n",
    "                            arcpy.env.workspace + r\"\\temp_trainpoly.shp\", \n",
    "                            arcpy.env.workspace + r\"\\temp_valpoly.shp\", 60, \"PERCENTAGE_OF_INPUT\")\n",
    "    #load each to get poly id\n",
    "    trainpolygdf = gpd.read_file(arcpy.env.workspace + r\"\\temp_trainpoly.shp\")\n",
    "    valpolygdf = gpd.read_file(arcpy.env.workspace + r\"\\temp_valpoly.shp\")\n",
    "    \n",
    "    #use subpolyid to select train/val points\n",
    "    trainptgdf = ptwithpolygdf[ptwithpolygdf['subpolyid'].isin(trainpolygdf['subpolyid'].tolist())]\n",
    "    valptgdf = ptwithpolygdf[ptwithpolygdf['subpolyid'].isin(valpolygdf['subpolyid'].tolist())]\n",
    "    \n",
    "    #write to temp\n",
    "    trainptgdf.to_file(arcpy.env.workspace + r\"\\temp_trainpoint.shp\")\n",
    "    valptgdf.to_file(arcpy.env.workspace + r\"\\temp_valpoint.shp\")\n",
    "    \n",
    "    #create trend surface\n",
    "    # Execute Trend\n",
    "    print('Creating trend surface...')\n",
    "    outTrend = Trend(arcpy.env.workspace + r\"\\temp_trainpoint.shp\", zField, cellSize, \n",
    "                     PolynomialOrder, regressionType)\n",
    "    outTrend.save(arcpy.env.workspace + r\"\\temp_trendraster.tif\")\n",
    "    \n",
    "    #Sample raster on validate points\n",
    "    print('Sampling trend surface...')\n",
    "    ExtractValuesToPoints(arcpy.env.workspace + r\"\\temp_valpoint.shp\", \n",
    "                          arcpy.env.workspace + r\"\\temp_trendraster.tif\", \n",
    "                          arcpy.env.workspace + r\"\\temp_valpoint_withdetrend.shp\",\n",
    "                          \"NONE\", \"VALUE_ONLY\")\n",
    "    \n",
    "    #read into gdf to eval\n",
    "    print('Evaluating trend surface...')\n",
    "    evalgdf = gpd.read_file(arcpy.env.workspace + r\"\\temp_valpoint_withdetrend.shp\")\n",
    "    #apply to DoD value (dod_unadj - trendRasterValue)\n",
    "    evalgdf['resid2'] = evalgdf['dod_unadj'] - evalgdf['RASTERVALU']\n",
    "    \n",
    "    #gather residuals grouped by polygons\n",
    "    data = {'bulk_pt_mean': [evalgdf['resid2'].mean()],\n",
    "            'bulk_pt_std': [evalgdf['resid2'].std()],\n",
    "            'all_poly_mean': [evalgdf.groupby('subpolyid')['resid2'].mean().mean()],\n",
    "            'all_poly_std': [evalgdf.groupby('subpolyid')['resid2'].mean().std()],\n",
    "            'paved_poly_mean': [evalgdf[evalgdf['type'] == 'paved'].groupby('subpolyid')['resid2'].mean().mean()],\n",
    "            'paved_poly_std': [evalgdf[evalgdf['type'] == 'paved'].groupby('subpolyid')['resid2'].mean().std()],\n",
    "            'unpaved_poly_mean': [evalgdf[evalgdf['type'] == 'unpaved'].groupby('subpolyid')['resid2'].mean().mean()],\n",
    "            'unpaved_poly_std': [evalgdf[evalgdf['type'] == 'unpaved'].groupby('subpolyid')['resid2'].mean().std()]\n",
    "           }\n",
    "    resultsdf = resultsdf.append(pd.DataFrame(data, \n",
    "                                              columns = ['bulk_pt_mean','bulk_pt_std','all_poly_mean','all_poly_std','paved_poly_mean','paved_poly_std','unpaved_poly_mean','unpaved_poly_std']), \n",
    "                                 ignore_index=True)\n",
    "    \n",
    "    \n",
    "    print(datetime.now().strftime(\"%Y/%d/%m %H:%M:%S\"))   \n",
    "        \n",
    "    #write intermediate output, overwrite to save progress\n",
    "    resultsdf.to_csv(r\"D:\\Whiskeytown\\dem_diff\\brandy_creek\\detrend_surface\\ResidualSystematicErrorBy_100m_SubPolygon_19-18.csv\")\n",
    "    resultsdf.describe().to_csv(r\"D:\\Whiskeytown\\dem_diff\\brandy_creek\\detrend_surface\\ResidualSystematicErrorBy_100m_SubPolygon_SummaryStats_19-18.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-effects",
   "metadata": {},
   "source": [
    "### Same as above, but using entire polygons instead of subidived polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "afraid-shoulder",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021/28/01 13:29:39\n",
      "Beginning iteration 0 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 13:31:19\n",
      "Beginning iteration 1 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 13:34:18\n",
      "Beginning iteration 2 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 13:35:43\n",
      "Beginning iteration 3 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 13:37:11\n",
      "Beginning iteration 4 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 13:39:40\n",
      "Beginning iteration 5 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 13:42:17\n",
      "Beginning iteration 6 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 13:45:16\n",
      "Beginning iteration 7 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 13:46:34\n",
      "Beginning iteration 8 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 13:49:18\n",
      "Beginning iteration 9 ...\n",
      "Creating trend surface...\n",
      "Sampling trend surface...\n",
      "Evaluating trend surface...\n",
      "2021/28/01 13:50:41\n"
     ]
    }
   ],
   "source": [
    "#iterate and do test/train splits to evaluate by whole polygon\n",
    "print(datetime.now().strftime(\"%Y/%d/%m %H:%M:%S\"))    \n",
    "#number of iterations (~2-3 minutes each?)\n",
    "num_loops = 10\n",
    "#inputs\n",
    "pointswithsubpolyid = r\"D:\\Whiskeytown\\dem_diff\\brandy_creek\\dod\\shp\\DoD_20-19_unadj_pts_stable_subpolyid.shp\"\n",
    "# stablepolysubdivided = r\"D:\\Whiskeytown\\dem_diff\\brandy_creek\\shp\\Stable_poly_19-20_expanded_subdivided.shp\"\n",
    "stablepolysubdivided = r\"D:\\Whiskeytown\\dem_diff\\brandy_creek\\shp\\Stable_poly_19-20_expanded.shp\"\n",
    "\n",
    "#load points with subpoly id into gdf to be filtered\n",
    "ptwithpolygdf = gpd.read_file(pointswithsubpolyid)\n",
    "\n",
    "#trend surface details\n",
    "zField = \"dod_unadj\"\n",
    "cellSize = 0.25\n",
    "PolynomialOrder = 2\n",
    "regressionType = \"LINEAR\"\n",
    "\n",
    "#result df\n",
    "resultsdf = pd.DataFrame(columns = ['bulk_pt_mean','bulk_pt_std','all_poly_mean','all_poly_std','paved_poly_mean','paved_poly_std','unpaved_poly_mean','unpaved_poly_std'])\n",
    "#percent of poly to use for train \n",
    "trainfrac = 0.6\n",
    "\n",
    "for i in range(num_loops):\n",
    "    #clean up scratch dir first (leave results of final iteration in scratch to let user see them)\n",
    "    for fn in [r\"\\temp_trainpoly.shp\", r\"\\temp_valpoly.shp\", r\"\\temp_trainpoint.shp\", r\"\\temp_valpoint.shp\", r\"\\temp_valpoint_withdetrend.shp\",r\"\\temp_trendraster.tif\"]:\n",
    "        arcpy.management.Delete(arcpy.env.workspace + fn)\n",
    "    print(f'Beginning iteration {i} ...')\n",
    "    #subset poly to test/train\n",
    "    arcpy.ga.SubsetFeatures(stablepolysubdivided, \n",
    "                            arcpy.env.workspace + r\"\\temp_trainpoly.shp\", \n",
    "                            arcpy.env.workspace + r\"\\temp_valpoly.shp\", 60, \"PERCENTAGE_OF_INPUT\")\n",
    "    #load each to get poly id\n",
    "    trainpolygdf = gpd.read_file(arcpy.env.workspace + r\"\\temp_trainpoly.shp\")\n",
    "    valpolygdf = gpd.read_file(arcpy.env.workspace + r\"\\temp_valpoly.shp\")\n",
    "    \n",
    "    #use subpolyid to select train/val points\n",
    "    trainptgdf = ptwithpolygdf[ptwithpolygdf['id'].isin(trainpolygdf['id'].tolist())]\n",
    "    valptgdf = ptwithpolygdf[ptwithpolygdf['id'].isin(valpolygdf['id'].tolist())]\n",
    "    \n",
    "    #write to temp\n",
    "    trainptgdf.to_file(arcpy.env.workspace + r\"\\temp_trainpoint.shp\")\n",
    "    valptgdf.to_file(arcpy.env.workspace + r\"\\temp_valpoint.shp\")\n",
    "    \n",
    "    #create trend surface\n",
    "    # Execute Trend\n",
    "    print('Creating trend surface...')\n",
    "    outTrend = Trend(arcpy.env.workspace + r\"\\temp_trainpoint.shp\", zField, cellSize, \n",
    "                     PolynomialOrder, regressionType)\n",
    "    outTrend.save(arcpy.env.workspace + r\"\\temp_trendraster.tif\")\n",
    "    \n",
    "    #Sample raster on validate points\n",
    "    print('Sampling trend surface...')\n",
    "    ExtractValuesToPoints(arcpy.env.workspace + r\"\\temp_valpoint.shp\", \n",
    "                          arcpy.env.workspace + r\"\\temp_trendraster.tif\", \n",
    "                          arcpy.env.workspace + r\"\\temp_valpoint_withdetrend.shp\",\n",
    "                          \"NONE\", \"VALUE_ONLY\")\n",
    "    \n",
    "    #read into gdf to eval\n",
    "    print('Evaluating trend surface...')\n",
    "    evalgdf = gpd.read_file(arcpy.env.workspace + r\"\\temp_valpoint_withdetrend.shp\")\n",
    "    #apply to DoD value (dod_unadj - trendRasterValue)\n",
    "    evalgdf['resid2'] = evalgdf['dod_unadj'] - evalgdf['RASTERVALU']\n",
    "    \n",
    "    #gather residuals grouped by polygons\n",
    "    data = {'bulk_pt_mean': [evalgdf['resid2'].mean()],\n",
    "            'bulk_pt_std': [evalgdf['resid2'].std()],\n",
    "            'all_poly_mean': [evalgdf.groupby('id')['resid2'].mean().mean()],\n",
    "            'all_poly_std': [evalgdf.groupby('id')['resid2'].mean().std()],\n",
    "            'paved_poly_mean': [evalgdf[evalgdf['type'] == 'paved'].groupby('id')['resid2'].mean().mean()],\n",
    "            'paved_poly_std': [evalgdf[evalgdf['type'] == 'paved'].groupby('id')['resid2'].mean().std()],\n",
    "            'unpaved_poly_mean': [evalgdf[evalgdf['type'] == 'unpaved'].groupby('id')['resid2'].mean().mean()],\n",
    "            'unpaved_poly_std': [evalgdf[evalgdf['type'] == 'unpaved'].groupby('id')['resid2'].mean().std()]\n",
    "           }\n",
    "    resultsdf = resultsdf.append(pd.DataFrame(data, \n",
    "                                              columns = ['bulk_pt_mean','bulk_pt_std','all_poly_mean','all_poly_std','paved_poly_mean','paved_poly_std','unpaved_poly_mean','unpaved_poly_std']), \n",
    "                                 ignore_index=True)\n",
    "    \n",
    "    \n",
    "    print(datetime.now().strftime(\"%Y/%d/%m %H:%M:%S\"))  \n",
    "    \n",
    "    #write intermediate output, overwrite to save progress\n",
    "    resultsdf.to_csv(r\"D:\\Whiskeytown\\dem_diff\\brandy_creek\\detrend_surface\\ResidualSystematicErrorByWholePolygon_20-19.csv\")\n",
    "    resultsdf.describe().to_csv(r\"D:\\Whiskeytown\\dem_diff\\brandy_creek\\detrend_surface\\ResidualSystematicErrorByWholePolygon_SummaryStats_20-19.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-pastor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
